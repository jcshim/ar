## 다층 PCB 보드에 대해 실시간 라우팅을 수행하며, 강화학습을 활용하고 
## KiCAD 툴에 통합 가능한 방식으로 딥러닝 기반 Auto Routing 기법을 조사

### 어떤 딥러닝 구조가 적합할지, 
### 실시간성과 성능을 어떻게 보장할 수 있을지, 
### KiCAD에 플러그인 혹은 확장으로 어떻게 통합할 수 있을지


# 다층 PCB 자동 배선을 위한 강화학습 접근 조사

다층 PCB 보드의 자동 배선은 수백 개의 신호선을 **다층** 기판에서 **설계 규칙 준수** 하에 연결해야 하므로 매우 복잡한 NP-난해 문제입니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=In%20modern%20electronic%20manufacturing%20processes%2C,has%20been%20proved%20to%20b)). 최근 딥러닝, 특히 **심층 강화학습**(DRL)을 활용하여 배선 경로를 자동으로 최적화하려는 연구가 활발합니다. 본 보고서에서는 **실시간성**을 고려한 RL 알고리즘 구조, 다층 보드에서의 **via(비아)** 및 층간 전환 처리, 강화학습 **환경 설계**, 공개된 **데이터셋/시뮬레이터**, KiCAD와의 **연동 방법**, 그리고 관련 **프로젝트 및 논문 사례**를 정리합니다. 주요 접근법과 모델 특징은 말미의 표 1에 요약하였습니다.

## 1. 실시간 강화학습 구조 설계

**실시간성**을 갖춘 강화학습을 위해서는 *샘플 효율*과 *추론 속도*가 중요한데, 알고리즘 선택에 따라 달라집니다. **DQN**(Deep Q-Network) 계열은 *오프라인* 학습으로 경험 재사용이 가능하여 샘플 효율이 높고 실시간 추론이 빠른 장점이 있습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=problem%20as%20a%20Markov%20Decision,address%20the%20global%20routing%20problem)). 실제로 Liao 등 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=problem%20as%20a%20Markov%20Decision,address%20the%20global%20routing%20problem))은 **글로벌 라우팅** 문제에 DQN을 적용하여 하나의 Q-네트워크로 여러 신호망(net)을 **동시 최적화(conjoint optimization)** 하는 정책을 학습시켰습니다. 이 방식은 기존 A* 기반 순차 배선보다 복잡한 경우에서 우수한 결과를 내며, DQN의 **경험 재현(buffer)**으로 실시간 활용이 가능함을 보였습니다 ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=This%20project%20is%20based%20on,multipin%20decomposition)). 다만 DQN은 **Q값 과추정** 문제가 있어 Double-DQN 등의 개선이 필요하다고 보고되기도 합니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=match%20at%20L824%20research%2C%20the,used%20in%20our%20current%20approach)).

한편, **PPO**(Proximal Policy Optimization)나 **A3C**(Asynchronous Advantage Actor-Critic) 같은 *정책 기반* 알고리즘은 샘플 효율은 다소 낮아도 학습 안정성이 높습니다. He 등은 MCTS(몬테카를로 트리 탐색)와 결합된 **PPO** 정책을 사용하여 경로 탐색을 효율화하였는데, PPO는 구현이 비교적 간단하고 수렴이 빠르며 샘플 복잡도도 우수하여 선택되었다고 합니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=%28PPO%29%20,11)). 그 결과 순수 PPO나 순수 MCTS로는 실패하던 복잡한 배선 문제도 RL 가이드가 포함된 MCTS로는 해결할 수 있었습니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=shortest%20path%20for%20the%20current,The%20search%20space%20is%20too)). **A3C**의 경우 멀티스레딩으로 다수의 에이전트가 병렬 학습하므로 *학습 가속*에 유리하며, 실시간 시스템에 빠르게 적응하는 모델을 얻는 데 도움이 될 수 있습니다. 예컨대 **AutoRoute-GNN**이라는 접근에서는 그래프 신경망(GNN)을 통합한 다중 에이전트 RL 구조를 제안하여 일반화 능력을 높이고자 하였습니다 ([Deep Reinforcement Learning meets Graph Neural Networks - arXiv](https://arxiv.org/abs/1910.07421#:~:text=Deep%20Reinforcement%20Learning%20meets%20Graph,action%20space%20to%20enable%20generalization)).

**모델 경량화**도 실시간성에 중요합니다. Liao 등의 DQN 라우터는 입력 상태를 12차원 벡터로 설계하고, 출력 액션도 6개로 제한하여 비교적 **경량 신경망**(은닉층 3개, 32-64-32 유닛)으로 구현했습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=match%20at%20L420%20Network%20Architecture%3A,output%20size%20is%206%2C%20aligned)). 반면 복잡한 상황까지 다루기 위해 CNN이나 트랜스포머를 쓰는 경우 추론 시간이 늘 수 있으므로, 경로 탐색시 **휴리스틱**과 RL을 혼합하는 방식도 고려됩니다. He 등의 1단계 방법은 MCTS를 RL 정책으로 *롤아웃*하여 탐색 효율을 높였고 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=The%20research%20includes%20three%20parts,learning%20policy%20in%20the%20rollout)), 2단계에서는 전통 알고리즘(A* 기반 상세 배선)과 연계하는 **하이브리드 구조**로 실용성과 속도를 확보했습니다 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=In%20the%20second%20part%2C%20we,a%20global%20routing%20solution%20exists)) ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=routing%20methodology,a%20global%20routing%20solution%20exists)). 이처럼 RL을 핵심으로 하되 필요시 탐색 알고리즘과 결합하거나, 사전에 학습된 정책을 활용해 **온디맨드 경로계획**에 즉시 적용함으로써 실시간 요구에 부응할 수 있습니다.

## 2. 다층 PCB 및 비아(Via) 처리 전략

다층 PCB에서는 신호를 다른 층으로 넘기는 **비아(via)**의 사용과 층간 전환이 필수적입니다. RL 기반 자동배선에서 이를 다루는 일반적인 방법은 **동작 공간에 층변경 액션을 추가**하는 것입니다. 예를 들어 Bao 등은 배선 에이전트의 행동으로 상하좌우 이동 외에 **위층 상승** 및 **아래층 하강** 2가지 추가 동작을 넣어, 3차원 격자에서의 경로 확장을 가능케 했습니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=Fig,a%20path%20perpendicular%20to%20layers)). 이러한 액션을 선택하면 해당 지점에 비아를 형성하여 레이어를 바꾸는 식으로 다층 경로를 형성합니다. 강화학습 모델은 학습을 통해 **필요 최소한의 비아**만 쓰도록 전략을 익히게 됩니다.

다층 배선에서는 **비아 최소화**와 **배선 층별 분리** 등이 중요합니다. RL의 보상 함수에서 **비아 개수에 패널티**를 주어 비아 남용을 억제할 수 있습니다. FanoutNet 연구에서는 보상에 배선 **접속률(routability)**, **배선 길이**, **비아 개수** 등을 반영하여, 결과적으로 상용 툴 대비 더 적은 비아로 배선을 완료했습니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=,1%20111%2055%2063%2050)). 실제 실험에서 FanoutNet은 평균 비아 수를 기존 프리라우터(FR) 대비 크게 감소시켜 모든 벤치마크에서 **100% 배선 성공**을 달성했습니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=,1%20111%2055%2063%2050)). 이처럼 보상 함수로 비아 사용을 비용화하면 RL 에이전트가 자연스럽게 비아를 아껴 쓰는 경향을 학습합니다.

또한 RL 에이전트 스스로 **층별 배선 전략**을 발견하기도 합니다. DeepPCB 프로젝트 팀에 따르면, RL로 학습된 에이전트가 한 층은 **가로 배선 전용**, 다른 층은 **세로 배선 전용**으로 활용하는 **교차 배선 패턴**을 스스로 찾아낸 사례가 있다고 합니다 ([EEVblog 1535 - DeepPCB AI AutoRouting TESTED! - Page 1](https://www.eevblog.com/forum/blog/eevblog-1535-deeppcb-ai-autorouting-tested!/#:~:text=,try%20another%20run%20with%20it)). 이는 인간 설계자들이 복잡한 보드에서 흔히 사용하는 전략으로, 강화학습이 충분한 경험을 통해 이러한 **패턴 학습**도 가능함을 보여줍니다. 다층 PCB의 **전원면(plane)**이나 **차동 신호선**처럼 특수한 배선도 RL로 처리하려는 시도가 있으며, Quilter 프로젝트에서는 물리 시뮬레이션을 병행하여 고속/고전류 배선도 처리하도록 연구하고 있습니다 ([Quilter - Quilter community forums](https://community.quilter.ai/#:~:text=34%20%20%20%20,October%202%2C%202024%20%2036)) ([Quilter - Quilter community forums](https://community.quilter.ai/#:~:text=Quilter%20can%20now%20route%20differential,pairs)).

## 3. 강화학습 환경 설계 (상태 공간, 행동 공간, 보상 정의)

효과적인 RL 적용을 위해서는 **환경 모델링**이 중요합니다. **상태(state)**는 보통 현재까지의 배선 진행 상황과 목표 정보를 포함해야 합니다. 단순한 접근으로는 에이전트가 현재 배선 중인 **핀 간 경로**의 헤드 위치와 목표까지의 맨해튼 거리, 주변 장애물 유무 등을 포함한 **피처 벡터**로 상태를 표현할 수 있습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=Network%20Architecture%3A%20The%20Q,output%20size%20is%206%2C%20aligned)). 예컨대 Liao 등의 DQN 라우터는 12개의 요소로 구성된 상태벡터를 설계하였는데, 이는 경로상의 충돌 여부, 목표 방향, 남은 배선 등 핵심 정보를 함축한 것입니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=Network%20Architecture%3A%20The%20Q,output%20size%20is%206%2C%20aligned)). 보다 풍부한 표현으로는 PCB 보드를 격자(grid)로 모델링하여 **이미지 맵** 형태로 주는 방법이 있습니다. FanoutNet에서는 PCB 레이아웃과 회로망(netlist)을 CNN과 어텐션 네트워크로 **인코딩**하여 상태로 사용하였고, 이를 통해 배선 전 **팬아웃(fanout)** 단계의 결정을 내렸습니다 ([[PDF] FanoutNet: A Neuralized PCB Fanout Automation Method Using ...](https://ojs.aaai.org/index.php/AAAI/article/view/26030/25802#:~:text=,make%20decisions%20and%20evaluations)). 이처럼 **Convolution**을 이용하면 배선 영역의 **공간적 특성**(부품, 패드, 이미 놓인 배선 등)을 포착할 수 있습니다. 또 다른 방법으로 **그래프 신경망(GNN)**을 활용해 상태를 표현하면, 보드의 패드노드와 연결관계를 그래프로 보고 학습할 수 있습니다. 예를 들어 한 연구에서는 RL 에이전트에 GNN을 통합하여 임의의 회로 토폴로지에 일반화된 정책 학습을 시도하였는데 ([Deep Reinforcement Learning meets Graph Neural Networks - arXiv](https://arxiv.org/abs/1910.07421#:~:text=Deep%20Reinforcement%20Learning%20meets%20Graph,action%20space%20to%20enable%20generalization)), 이러한 **그래프 기반 상태 표현**은 배선 문제처럼 **동적 노드 연결** 특성이 있는 환경에 유망합니다.

**행동(action)** 공간은 경로 탐색에서 에이전트가 취할 수 있는 선택지를 나타냅니다. 일반적으로 **격자형 모델**에서는 상하좌우 이동 (4방향) 및 필요 시 층 변경(위/아래)까지 **6가지 이산 액션**으로 정의됩니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=Fig,a%20path%20perpendicular%20to%20layers)). 실제 DQN 라우터 구현에서도 출력 뉴런 수를 6으로 두어 이 6방향 이동을 각각 Q값으로 평가하였습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=Network%20Architecture%3A%20The%20Q,output%20size%20is%206%2C%20aligned)). 행동 중에는 잘못된 배선으로 **충돌**을 일으키는 불법 움직임도 있을 수 있는데, 이러한 경우 해당 액션을 선택하지 못하도록 마스킹하거나 선택시 즉각 **큰 음의 보상**으로 실패를 학습시킵니다. 경우에 따라 에이전트가 특정 배선을 **완료**하거나 **포기**하는 액션 (예: 목표 핀에 도달하여 해당 net 종료)도 정의할 수 있습니다. 그러나 대부분의 접근은 “목표 핀에 도달” 상태를 **종료 조건**으로 처리하여 에피소드를 끝내고 다음 net으로 넘어가는 식으로 구현합니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=path%20to%20a%20non,the%20path%20Pn%20is%20updated)). **멀티 핀(net)**의 경우 핀쌍 분해 후 스테이너 트리로 통합하거나, 또는 에이전트가 하나의 net의 모든 핀을 연결할 때까지 순차적으로 행동하도록 상태를 구성하기도 합니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=A%20routing%20problem%20is%2C%20given,9)).

**보상(reward)** 설계는 에이전트의 학습 목표를 결정합니다. 일반적으로 **성공적인 연결**에는 큰 **양의 보상**을 주고, 경로를 연장할 때마다 **작은 비용(음의 보상)**을 부여하여 불필요한 경로 연장을 억제합니다. 또한 **비아 사용**에도 패널티를 추가하여, 에이전트가 via 액션(층 변경)을 쓸 때마다 약간의 보상 감소가 일어나도록 합니다. Bao 등의 연구에서는 최종 상태에서 각 net이 연결된 정도와 경로 길이에 기반한 보상 함수를 사용하였는데, 성공 연결 수를 늘리고 경로 길이를 줄이는 방향으로 보상을 설계했습니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=R,%E2%88%92%20%CE%B2RL%20%E2%88%91%20N%E2%88%88Nb)). DQN 라우터에서는 **에피소드 종료 시** 두 핀이 연결되었다면 높은 보상을, 실패했거나 충돌로 중단되었다면 큰 페널티를 주되, 학습 시에는 **성공/실패 경로 모두** 학습에 활용하여 효율을 높였습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=match%20at%20L410%20As%20the,high%2C%20positive%20reward)) ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=As%20the%20Q,high%2C%20positive%20reward)). 더욱 고도화된 보상으로는 **전체 보드의 완성도**나 **잔여 배선의 난이도**까지 고려할 수 있습니다. 예를 들어 FanoutNet은 각 행동 후 **예상 배선 가능성(Pre-routability)**을 계산하여 보상에 반영함으로써, **초기에 배선 불가능한 패턴**을 피하도록 유도했습니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=Context%201)). 이처럼 보상에 **전역적 성공 지표**를 넣으면, 에이전트가 단순히 현재 net 연결뿐만 아니라 **향후 남은 배선의 용이성**까지 고려한 결정을 내릴 수 있습니다.

## 4. 공개 데이터셋 및 시뮬레이션 환경

PCB 배선용 강화학습을 연구하기 위해서는 적절한 **훈련/평가용 데이터**와 **시뮬레이션 환경**이 필요합니다. 과거에는 표준화된 PCB **벤치마크 부족**이 문제로 지적되어 왔지만 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=routing%20algorithms%20are%20typically%20specialized,world%20PCB%20designs)) ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=In%20the%20third%20part%2C%20we,based%20PCB%20routing%20algorithms)), 최근 이러한 한계를 해소하기 위한 노력들이 있습니다. 2024년 He 등의 연구에서는 **커뮤니티가 공개한 실제 PCB 디자인**을 모아 대규모 데이터셋을 구축하였다고 보고합니다 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=In%20the%20third%20part%2C%20we,based%20PCB%20routing%20algorithms)). 이 데이터셋은 JSON 포맷으로 배선 관련 지geometry만 추출한 것으로, 최신 논문들이 쓰던 데이터셋보다 **100배 이상 규모가 크며**, 다양한 입력 포맷(KiCAD 등)을 지원하는 스크립트로 확장 가능하도록 만들었다고 합니다 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=In%20the%20third%20part%2C%20we,based%20PCB%20routing%20algorithms)). 이러한 **오픈소스 PCB 디자인 데이터셋**은 향후 RL 기반 배선 알고리즘들의 성능을 공정하게 비교하고 재현성을 높이는 데 기여할 것으로 기대됩니다.

학술 연구에서는 자체적으로 **문제 생성기**를 만들어 데이터를 확보하기도 했습니다. 예를 들어 Liao 등은 임의 크기의 격자 보드에 무작위로 패드와 넷을 배치하여 **글로벌 라우팅 문제 생성기**를 개발했고, 이를 통해 다양한 난이도의 훈련용 에피소드를 자동 생성했습니다 ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=,DQN%20Router)). 이렇게 생성된 문제 세트는 오픈소스로 공개되어 있어 연구자들이 자유롭게 활용할 수 있습니다 ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=This%20project%20is%20based%20on,multipin%20decomposition)). FanoutNet 연구진도 실험에 오픈소스 데이터셋을 사용했다고 명시하는데, 논문에 언급된 *bm1*–*bm11* 보드 케이스들이 이에 해당합니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=...%20we%20use%20Pre,)). 이들은 다층 PCB의 팬아웃 및 배선 문제를 포함한 데이터로서, 연구 결과 비교에 활용되었습니다.

**시뮬레이션 환경** 측면에서는, Iowa State Univ. 연구팀이 공개한 **강화학습 환경**이 주목됩니다. 이 환경은 다양한 PCB 배선 문제를 실험하고 RL 알고리즘을 테스트할 수 있도록 높은 구성 유연성을 갖추고 있으며, 배선 문제 인스턴스를 손쉽게 추가할 수 있다고 합니다 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=Notably%2C%20our%20dataset%20is%20100,based%20PCB%20routing%20algorithms)). 사용자는 해당 환경에서 상태/액션/보상 함수를 커스터마이징하여 자신만의 에이전트를 훈련할 수 있고, 환경은 KiCAD 등의 설계 데이터를 받아들여 **시뮬레이션 보드**를 구성합니다. 이처럼 RL 연구를 위한 **공개 시뮬레이터**가 마련되면서, 재현성과 비교 연구가 한층 수월해지고 있습니다.

한편, 상용 배선 도구인 **FreeRouting**도 연구 커뮤니티에서 자주 baseline으로 활용됩니다. FreeRouting은 오픈소스 **전통 휴리스틱** 자동배선기로, Specctra DSN 형식 입출력을 지원합니다. RL 에이전트의 결과를 검증하거나 초기 배선도를 생성하는 용도로 FreeRouting을 활용하고, 성능 비교 지표로 **완성률, 비아수, 총 배선길이** 등을 비교 평가하기도 합니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=,1%20111%2055%2063%2050)). 예를 들어 EEVblog 포럼에서는 한 사용자가 DeepPCB의 결과와 FreeRouting 결과를 비교하려 DSN 파일을 요청하기도 했습니다 ([EEVblog 1535 - DeepPCB AI AutoRouting TESTED! - Page 1](https://www.eevblog.com/forum/blog/eevblog-1535-deeppcb-ai-autorouting-tested!/#:~:text=Quote%20from%3A%20bbrand67%20on%20March,29%2C%202023%2C%2002%3A57%3A34%20pm)). 이렇듯 **기존 알고리즘**과의 비교를 통해 RL 접근의 장단점을 객관적으로 파악할 수 있습니다.

## 5. KiCAD와의 연동 전략

KiCAD와 RL 기반 자동배선기의 **통합**은 여러 가지 방식으로 이루어질 수 있습니다. KiCAD는 기본적으로 자체 자동배선 엔진을 포함하지 않지만, **외부 툴 연동**이 가능하도록 설계되어 있습니다 ([no autorouting in KiCad?! - Reddit](https://www.reddit.com/r/KiCad/comments/icqvfi/no_autorouting_in_kicad/#:~:text=no%20autorouting%20in%20KiCad%3F%21%20,0%20versions)). 가장 대표적인 방법은 KiCAD의 **Specctra DSN/SES 인터페이스**를 활용하는 것입니다. KiCAD PCBnew에서 보드와 넷리스트를 DSN 파일로 내보낸 후, RL 자동배선기가 이 DSN을 입력으로 받아 경로 최적화를 수행하고, 완료된 배선은 SES 파일로 반환하는 방식입니다. 실제 상용 서비스인 DeepPCB도 KiCAD 보드를 지원하며, 사용자가 DSN 파일을 업로드하면 24시간 내에 자동 배선된 SES 결과를 돌려주는 흐름이었습니다 ([DeepPCB Routes Your KiCAD PCBs | Hackaday](https://hackaday.com/2019/12/01/deeppcb-routes-your-kicad-pcbs/#:~:text=First%2C%20it%20supports%20KiCAD,few%20examples%20already%20worked%20out)). 이러한 파일 교환 방식은 **표준 포맷**을 사용하므로 구현이 비교적 쉽고, KiCAD뿐 아니라 Altium 등 다른 EDA 툴과도 유사하게 연계할 수 있다는 장점이 있습니다.

또 다른 접근은 KiCAD의 **Python API**나 **플러그인 시스템**을 이용하는 것입니다. KiCAD PCBnew에는 배치 및 배선 객체를 스크립트로 조작할 수 있는 Python 바인딩이 제공되어 ([PCB Python Bindings - Developer Documentation | KiCad](https://dev-docs.kicad.org/en/apis-and-binding/pcbnew/index.html#:~:text=PCB%20Python%20Bindings%20,from%20within%20the%20PCB%20editor)), 이를 통해 사용자가 작성한 RL 에이전트 코드를 플러그인 형태로 실행할 수 있습니다. 예를 들어, RL 알고리즘은 독립 실행되면서 KiCAD API를 호출해 **실시간으로 트랙을 추가**하거나 **비아를 삽입**할 수 있습니다. 이 경우 KiCAD의 DRC(설계 규칙 검사) 기능을 API로 활용하여, 에이전트가 행동을 취할 때마다 해당 액션의 즉각적인 합법성(예: 간격 위반 여부)을 피드백으로 받을 수도 있습니다 ([KiCad Racetrack Layout with Python Plugin - Jeff McBride](https://jeffmcbride.net/kicad-track-layout/#:~:text=KiCad%20Racetrack%20Layout%20with%20Python,)). 한 Reddit 사례에서는 Python으로 트랙과 비아를 자동 생성하는 스크립트를 작성해 배선을 일부 자동화한 예가 있는데 ([Python script to route tracks, round tracks, create vias, edge ... - Reddit](https://www.reddit.com/r/KiCad/comments/wt8iwm/python_script_to_route_tracks_round_tracks_create/#:~:text=Python%20script%20to%20route%20tracks%2C,who%20want%20to%20automate)), 이를 확장하여 RL 에이전트의 행동을 스크립트로 구현하면 KiCAD 내에서 배선을 **인터랙티브**하게 진행시키는 것도 가능합니다.

만약 RL 알고리즘을 완전히 **외부 프로그램**으로 두고 싶다면, KiCAD의 **명령행(CLI) 인터페이스**나 **서버 모드**를 이용할 수도 있습니다. KiCAD 7부터는 PCBnew를 헤드리스(headless)로 구동하며 Python을 통한 조작을 받을 수 있는 모드가 논의되고 있으며 ([KiCad API Python Bindings - GitLab](https://gitlab.com/kicad/code/kicad-python#:~:text=KiCad%20API%20Python%20Bindings%20,interact%20with%20a%20running)), 이를 활용하면 RL 에이전트가 KiCAD를 백엔드 엔진처럼 호출해 배선 결과를 파일로 저장하게 할 수 있습니다. 즉, 에이전트는 현재까지의 배선상태를 KiCAD로부터 읽어와 상태로 삼고, 결정된 액션(예: 어떤 net의 어떤 지점에 어떤 트랙을 놓을지)을 KiCAD에 전달하여 실행, 그 결과를 다시 받아오는 **교호 연동**도 생각해볼 수 있습니다. 다만 이러한 방식을 실시간으로 수행하려면 KiCAD 쪽의 처리속도와 통신 지연도 고려해야 합니다.

정리하면, **(a)** DSN/SES 파일을 통한 배치(batch) 방식 통합 ([DeepPCB Routes Your KiCAD PCBs | Hackaday](https://hackaday.com/2019/12/01/deeppcb-routes-your-kicad-pcbs/#:~:text=First%2C%20it%20supports%20KiCAD,few%20examples%20already%20worked%20out)), **(b)** KiCAD 플러그인/API를 통한 실시간 제어 방식, **(c)** 외부 툴로 KiCAD를 구동하는 하이브리드 방식 등이 있으며, 각각 구현 난이도와 실시간성, 편의성에 차이가 있습니다. 초기 연구 단계에서는 DSN 기반으로 결과를 받아보는 게 간단하며, 향후 상용 툴로 발전시키려면 플러그인 형태로의 제공도 고려할 수 있습니다.

## 6. 관련 프로젝트 및 연구 사례

마지막으로, **유사한 프로젝트와 논문 사례**를 살펴보겠습니다. Table 1에는 주요 접근법 몇 가지를 비교 정리했습니다. 

- **DeepPCB (InstaDeep)**: 앞서 언급한 클라우드 기반 AI 자동배선 서비스입니다. *강화학습*으로 에이전트를 훈련해 사용자 보드를 자동으로 배선하며, 초기에 품질이 낮더라도 반복 개선하는 특징을 보였습니다. DeepPCB 개발진은 “우리 배선기는 **강화학습**을 사용하며 시행착오를 통해 학습한다”라고 밝혔는데 ([EEVblog 1535 - DeepPCB AI AutoRouting TESTED! - Page 1](https://www.eevblog.com/forum/blog/eevblog-1535-deeppcb-ai-autorouting-tested!/#:~:text=found.%20,first%20solutions%20that%20you%20saw)), 초판 솔루션이 미흡했던 것은 학습 초기단계의 중간 결과였기 때문이라고 합니다. 실제로 EEVblog 테스트에서 DeepPCB는 처음에는 다소 무질서한 배선을 보였으나 시간 경과에 따라 개선된 결과를 제시했습니다. DeepPCB는 KiCAD 및 Altium과 연계되었으며, 현재는 InstaDeep에 의해 상용화를 준비 중인 것으로 알려집니다.

- **Quilter AI**: 2023년에 설립된 스타트업 Quilter는 PCB **배치+배선**을 통합적으로 자동화하는 플랫폼을 개발하고 있습니다. 이 회사는 **강화학습과 물리 시뮬레이션**을 결합하여 “인간을 능가하는 회로보드 설계자”를 목표로 삼고 있습니다 ([Technology](https://www.quilter.ai/technology#:~:text=Quilter%20uses%20reinforcement%20learning%20informed,automated%2C%20superhuman%20circuit%20board%20designer)). Quilter에 따르면 자사의 RL 디자이너는 인간보다 100배 빠른 속도로 배치를 완료하고 몇 시간 내에 새로운 설계안을 제시할 수 있다고 합니다 ([Technology](https://www.quilter.ai/technology#:~:text=)). 이 플랫폼은 전자기 **Full-wave** 해석기를 내장하여 배선된 보드의 신호 무결성, 전력 무결성 등을 체크하고, 그 피드백을 RL 설계에 활용하는 것이 특징입니다 ([Technology](https://www.quilter.ai/technology#:~:text=)) ([Technology](https://www.quilter.ai/technology#:~:text=Image)). 현재 Quilter는 베타 테스트 중이며, 클라우드 기반 웹 인터페이스를 통해 서비스를 제공하고 있습니다.

- **MCTS+DRL (Bao et al.)**: Forrest Bao를 주축으로 한 연구진은 배선을 **MCTS(트리 탐색)** 문제로 보고, 시뮬레이션 단계에서 **PPO 정책**을 활용하는 방법을 제안했습니다 ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=The%20research%20includes%20three%20parts,learning%20policy%20in%20the%20rollout)). 이 접근법은 강화학습 정책만으로 배선을 할 경우 경로 탐색 실패가 잦은 문제를 해결하고자, **MCTS 탐색에 RL을 가이드**로 삽입한 형태입니다. 실험 결과 순수 PPO 모델이나 기존 MCTS에 비해 **100% 성공률**로 모든 넷을 연결했고, 배선 길이도 거의 최단에 가깝게 유지해 줬습니다 ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=shortest%20path%20for%20the%20current,The%20search%20space%20is%20too)) ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=Our%20approach%20Sequential%20A,in%20some%20cases%20to%20make)). 특히 다층 배선에서도 검색 공간을 효율적으로 축소하여, PPO나 MCTS 단독으로는 시간 내 풀지 못하던 복잡한 보드도 풀어냈습니다. 해당 방법론은 NeurIPS 2022 워크샵 등을 통해 발표되었고, Iowa State Univ.의 PCB 디자인 자동화 프레임워크에 일부 통합되었습니다.

- **DQN 글로벌 라우터 (Liao et al.)**: CMU의 Liao 등이 발표한 방법으로, 비교적 초기(2019년)의 선구적 연구입니다. 여기서는 **Double DQN** 기반의 에이전트가 한 보드의 모든 넷을 한꺼번에 고려하여 배선하도록 학습되었습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=Q,a%20%E2%80%98best%E2%80%99%20action%20for%20the)). 독특한 점은 한 에이전트가 다수 넷의 **핀쌍 연결 순서까지 자율적으로 결정**하면서 전체 최적화를 달성한다는 점입니다. 이를 위해 상태에 현재 진행 중인 net과 남은 미연결 핀 정보를 포함시키고 Q함수가 어느 net의 어느 방향으로 진행할지를 평가하도록 설계되었습니다 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=Q,a%20%E2%80%98best%E2%80%99%20action%20for%20the)) ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=The%20main%20advantage%20of%20the,routing%20problem%20types%20is%20conducted)). 실험적으로 이 기법은 경로 자원이 부족한 경우(**혼잡한 보드**)에서 전통 A* 순차 연결보다 월등히 높은 완성도를 보였습니다 ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=,DQN%20Router)). 해당 연구의 코드와 문제생성기 역시 오픈소스로 공개되어 있어 ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=This%20project%20is%20based%20on,multipin%20decomposition)), 후속 연구에서 활용되고 있습니다.

- **FanoutNet (Li et al.)**: AAAI 2023에 발표된 최신 연구로, PCB 배선 중에서도 **팬아웃**(BGA 같은 고밀도 패키지에서 부품 핀을 보드 패턴으로 펼치는 단계)에 초점을 맞춘 강화학습 방법입니다. 이들은 CNN과 어텐션 기반 **이종 신경망**으로 PCB 레이아웃과 회로망을 표현하고, 이를 입력으로 **DDPG**(Deep Deterministic Policy Gradient, 연속형 RL) 계열 알고리즘을 사용해 각 핀의 via 위치와 배선 방향을 결정했습니다. FanoutNet은 오픈소스 예제 보드들로 평가했으며, 상용 툴 대비 **향상된 배선 용이성**을 달성했습니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=,1%20111%2055%2063%2050)). 특히 모든 케이스에서 배선 성공률 100%를 이루고 비아 수도 줄이는 등 뛰어난 결과를 보여, PCB 국부 배선 문제에 RL을 적용한 성공적 사례로 주목받고 있습니다.

이 외에도 PCB *부품 배치*를 강화학습으로 풀려는 시도 ([LukeVassallo/RL_PCB - GitHub](https://github.com/LukeVassallo/RL_PCB#:~:text=LukeVassallo%2FRL_PCB%20,PCB))나, 배선 문제를 **U-net 기반 딥러닝**으로 풀어 경로 탐색 시간을 줄이려는 연구 ([Unet-Astar: A Deep Learning-Based Fast Routing Algorithm for ...](https://www.researchgate.net/publication/374611747_Unet-Astar_A_Deep_Learning-Based_Fast_Routing_Algorithm_for_Unified_PCB_Routing#:~:text=Unet,algorithms%20in%20a%20simulated)) 등 다양한 접근들이 병행되고 있습니다. **Table 1**은 대표적인 모델들의 특징을 비교합니다.

| 모델 / 프로젝트            | 주요 기법 및 알고리즘                | 특징 및 성능                                 | 공개 여부         |
|----------------------------|------------------------------------|--------------------------------------------|-------------------|
| **DQN Global Router** (2019, CMU) ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=match%20at%20L420%20Network%20Architecture%3A,output%20size%20is%206%2C%20aligned)) ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=,DQN%20Router))  | DQN (경험재PLAY, \epsilon-greedy) <br> - 상태: 피처 벡터 (길이 12) <br> - 행동: 격자 6방향 (다층) | 순차 A* 대비 복잡보드 성능 우수 <br> Q값 과추정 완화 위해 Double-DQN 제안 ([[1906.08809] A DEEP REINFORCEMENT LEARNING APPROACH FOR GLOBAL ROUTING](https://ar5iv.org/pdf/1906.08809#:~:text=research%2C%20the%20conventional%20deep%20Q,used%20in%20our%20current%20approach)) | ✔ 코드 공개 ([GitHub - haiguanl/DQN_GlobalRouting: Applying Deep Q-learning for Global Routing](https://github.com/haiguanl/DQN_GlobalRouting#:~:text=This%20project%20is%20based%20on,multipin%20decomposition)) |
| **MCTS+PPO Hybrid** (2022, ISU) ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=%28PPO%29%20,11)) ([Circuit Routing Using Monte Carlo Tree Search and Deep Reinforcement Learning](https://forrestbao.github.io/publications/Circuit_Routing_Using_Monte_Carlo_Tree_Search_and_Deep_Reinforcement_Learning_VLSI_DAT_2022.pdf#:~:text=shortest%20path%20for%20the%20current,The%20search%20space%20is%20too))      | MCTS + PPO (on-policy 정책결합) <br> - 롤아웃 시 RL 정책 가이드 <br> - 백트래킹 및 가지치기로 탐색 효율↑ | 100% 배선 성공 (PPO 단독 실패한 사례 해결) <br> A* 대비 경로길이 유사, 비아 최소화 | ⬜ (논문 기법, 환경 공개 예정) |
| **FanoutNet** (2023, Wuhan) ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=,1%20111%2055%2063%2050))          | DRL + CNN/Attention 인코더 <br> - 알고리즘: DDPG 변형 (연속 행동)<br> - 대상: BGA 팬아웃 배선 국부 문제 | 상용 툴 대비 모든 케이스서 via↓, 용이성↑ <br> 복잡한 패키지에서도 자율 팬아웃 성공 | ⬜ (모델 비공개, 논문 결과) |
| **DeepPCB** (2019~, InstaDeep) ([EEVblog 1535 - DeepPCB AI AutoRouting TESTED! - Page 1](https://www.eevblog.com/forum/blog/eevblog-1535-deeppcb-ai-autorouting-tested!/#:~:text=found.%20,first%20solutions%20that%20you%20saw)) ([DeepPCB Routes Your KiCAD PCBs | Hackaday](https://hackaday.com/2019/12/01/deeppcb-routes-your-kicad-pcbs/#:~:text=First%2C%20it%20supports%20KiCAD,few%20examples%20already%20worked%20out))    | 강화학습 에이전트 + 클라우드 병렬탐색 <br> - 초기 해 해결 후 점진 개선 (온라인러닝)<br> - 목표: 전체 PCB 배치+배선 자율화 | 2-layer 보드 지원 (베타), KiCAD DSN 연동 <br> 초판 품질 낮으나 반복경험으로 개선 ([EEVblog 1535 - DeepPCB AI AutoRouting TESTED! - Page 1](https://www.eevblog.com/forum/blog/eevblog-1535-deeppcb-ai-autorouting-tested!/#:~:text=found.%20,first%20solutions%20that%20you%20saw))<br> (7시간 소요 보고 ([EEVblog 1535 - DeepPCB AI AutoRouting TESTED! - Page 1](https://www.eevblog.com/forum/blog/eevblog-1535-deeppcb-ai-autorouting-tested!/#:~:text=,first%20solutions%20that%20you%20saw))) | ✘ (상용 베타 서비스) |
| **Quilter** (2024, Startup) ([Technology](https://www.quilter.ai/technology#:~:text=Quilter%20uses%20reinforcement%20learning%20informed,automated%2C%20superhuman%20circuit%20board%20designer)) ([Technology](https://www.quilter.ai/technology#:~:text=))      | RL + 물리 시뮬레이션 (전문가 지식 반영) <br> - 멀티에이전트 배치·배선 + 전자기해석 피드백 <br> - 클라우드 스케일 아키텍처 | 인간 대비 100배 속도 주장 ([Technology](https://www.quilter.ai/technology#:~:text=))<br> 배선 품질 뿐 아니라 SI/PI까지 검증<br> DIff pair, 전원망 자동 배선 지원 | ✘ (클로즈드 베타) |

**표 1: 강화학습 기반 PCB 자동배선 주요 접근법 비교** (✔=소스 공개, ⬜=연구 단계, ✘=비공개/상용)

以上の 내용처럼, 다층 PCB 설계의 자동배선을 위한 강화학습 접근은 **알고리즘 설계**, **환경 구축**, **현업 연동** 등 다각도로 발전하고 있습니다. 비록 아직 상용 PCB 설계 툴에서 **보편적 기능**으로 자리잡지는 못했으나, 초기 연구들과 시범 시스템들은 RL 기반 배선이 충분히 실현 가능함을 보여주고 있습니다. 특히 복잡한 제약을 충족하는 배선 품질과 인간 전문가 수준의 전략 학습 측면에서 고무적인 결과들이 보고되고 있습니다 ([The open-source dataset used in the experiments | Download Scientific Diagram](https://www.researchgate.net/figure/The-open-source-dataset-used-in-the-experiments_tbl1_371923331#:~:text=,1%20111%2055%2063%2050)). 향후에는 더 표준화된 **벤치마크**와 **오픈소스 환경** ([Ph.D. Final Oral Exam: Youbiao He | Department of Computer Science](https://www.cs.iastate.edu/event/2024/phd-final-oral-exam-youbiao-he#:~:text=In%20the%20third%20part%2C%20we,based%20PCB%20routing%20algorithms))을 바탕으로 다양한 접근들의 성능이 검증되고, 배선 외의 부품 배치, 형상 최적화까지 통합한 **End-to-End PCB 설계 RL**로까지 연구가 확장될 것으로 기대합니다. 또한 KiCAD 등과의 긴밀한 연동을 통해, 연구 프로토타입이 **플러그인**이나 **클라우드 서비스** 형태로 전자설계 현장에 적용되어 **설계 생산성 향상**에 기여할 날도 머지않아 보입니다.

