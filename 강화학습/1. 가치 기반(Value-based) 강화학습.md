
# **가치 기반(Value-based) 강화학습**

---

## 💡 가치 기반(Value-based) 강화학습이란?

> "지금 뭘 하면 제일 이득일까?"를 **미리 계산해보고**, **그중 제일 좋은 행동을 선택하는 방식**이에요.

에이전트는 **상태(state)**에서 할 수 있는 **모든 행동(action)**에 대해  
"이걸 하면 얼마나 보상을 받을까?"를 숫자로 예측해요.  
이 숫자를 **Q값(Q-value)**라고 해요.

---

### ✅ 예시로 풀어보면:

#### 🎮 게임에서 몬스터를 만난 상황!
- **상태(state)**: "몬스터를 만남"
- **가능한 행동(action)**:
  1. 도망가기 → Q = 3
  2. 공격하기 → Q = 7
  3. 아이템 쓰기 → Q = 5

➡️ 에이전트는 이 중 **Q값이 가장 큰 "공격하기"를 선택**해요!

---

## 🔧 어떻게 학습하나요?

에이전트는 처음엔 Q값을 아무렇게나 추정해요.  
하지만 게임을 여러 번 해보며  
**보상을 받아본 경험을 바탕으로 Q값을 계속 업데이트**해요.

> 즉, “어제 공격해서 많이 맞았네... Q값 낮춰야지!”  
> “이번엔 도망가니 살아남았네~ Q값 올려야겠다!”

이렇게 하면서 **점점 더 똑똑한 선택**을 하게 돼요.

---

## 🧠 비유로 다시 한 번!

> 📘 시험공부하는 학생

- "이 문제는 지난 시험에 나왔고, 풀 수 있을 것 같아 → 점수 받을 확률 높음!"
- 그래서 그 문제를 집중적으로 공부함

→ 결국 **점수(Q값)가 높은 문제만 집중해서 좋은 결과**를 얻는 거예요.

---

## 📌 주요 알고리즘

### 1. **Q-Learning**  
- 상태-행동 쌍마다 Q값 테이블을 만듦
- 모든 Q값을 하나하나 저장함 (작은 문제에 적합)

### 2. **DQN (Deep Q-Network)**  
- Q값을 **딥러닝 신경망**으로 예측
- 큰 상태공간(예: 이미지, 센서 데이터 등)에서도 사용 가능

---

## 📍특징 정리

| 항목 | 설명 |
|------|------|
| 🌟 무엇을 학습하나요? | 상태-행동에 대한 Q값 |
| 🧠 정책은 어떻게 선택하나요? | Q값이 제일 높은 행동 선택 (Policy는 암묵적) |
| 🔢 행동 공간 | 주로 이산형 (ex. 위/아래/왼쪽/오른쪽) |
| 🤖 학습 특징 | 탐험(익숙하지 않은 행동 시도)과 이용(보상 높은 행동 선택) 간 균형 필요 |
